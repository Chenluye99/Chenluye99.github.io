<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=GBK" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Research</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="Bio.html">Biography</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-category">Miscellaneous</div>
<div class="menu-item"><a href="Miscellaneous.html">Misc.</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research</h1>
</div>
<h2>Papers and Preprints</h2>
<ol>
<li><p><a href="https://arxiv.org/abs/2402.07314" target=&ldquo;blank&rdquo;>A theoretical analysis of nash learning from human feedback under general kl-regularized preference</a> <br />
Chenlu Ye*, Wei Xiong*, Yuheng Zhang*, Hanze Dong*, Nan Jiang, Tong Zhang, <i>NeurIPS</i> 2024.</p>
</li>
<li><p><a href="https://arxiv.org/abs/2402.08991" target=&ldquo;blank&rdquo;>Towards robust model-based reinforcement learning against adversarial corruption</a> <br />
Chenlu Ye*, Jiafan He*, Quanquan Gu, Tong Zhang, <i>ICML</i> 2024.
An analysis of uncertainty-aware algorithms in the model-based framework under adversarial corruption and general function approximation.<br /><br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2312.11456" target=&ldquo;blank&rdquo;>Iterative preference learning from human feedback: Bridging theory and practice for rlhf under kl-constraint</a> <br />
Wei Xiong*, Hanze Dong*, Chenlu Ye*, Han Zhong, Nan Jiang, Tong Zhang, <i>ICML</i> 2024.<br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2311.13180" target=&ldquo;blank&rdquo;>Provably Efficient High-Dimensional Bandit Learning with Batched Feedbacks</a> <br />
Jianqing Fan*, Zhaoran Wang*, Zhuoran Yang*, Chenlu Ye*, Preprint.</p>
</li>
<li><p><a href="https://arxiv.org/abs/2310.14550" target=&ldquo;blank&rdquo;>Corruption-Robust Offline Reinforcement Learning with General Function Approximation</a> <br />
Chenlu Ye*, Rui Yang*, Quanquan Gu and Tong Zhang, <i>NeurIPS</i> 2023.</p>
</li>
<li><p><a href="https://arxiv.org/abs/2309.02476" target=&ldquo;blank&rdquo;>Optimal Sample Selection Through Uncertainty Estimation and Its Application in Deep Learning</a> <br />
Yong Lin*, Chen Liu*, Chenlu Ye*, Qing Lian, Yuan Yao and Tong Zhang, Preprint.</p>
</li>
<li><p><a href="https://arxiv.org/abs/2212.05949" target=&ldquo;blank&rdquo;>Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov Decision Processes</a> <br />
Chenlu Ye, Wei Xiong, Quanquan Gu and Tong Zhang, <i>ICML</i> 2023.</p>
</li>
</ol>
<p>(* equal contribution or alphabetical order)</p>
</td>
</tr>
</table>
</body>
</html>
